{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "003b_machine_learning_with_scikit_learn.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "LCQ5IM2Nt7EU"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/data-analytics-workshop/python/blob/master/003b_machine_learning_with_scikit_learn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5JsOY7DWVS7",
        "colab_type": "text"
      },
      "source": [
        "# Machine Learning with Scikit-Learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGRZ7KBydODb",
        "colab_type": "text"
      },
      "source": [
        "Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use to perform a specific task without using explicit instructions, relying on patterns and inference instead. It is seen as a subset of artificial intelligence. Machine learning algorithms build a mathematical model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to perform the task. Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or infeasible to develop a conventional algorithm for effectively performing the task.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-daFkl9V7H8g",
        "colab_type": "text"
      },
      "source": [
        "Scikit-learn is a free machine learning library for Python. It features various algorithms like support vector machine, random forests, and k-neighbours, and it also supports Python numerical and scientific libraries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuMahuoTWYKI",
        "colab_type": "text"
      },
      "source": [
        "Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rc1dFIvAVkgJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Library for Data Manipulation\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chFV2XFghGsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Library for Visualization\n",
        "import matplotlib. pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybRCtj0Udx90",
        "colab_type": "text"
      },
      "source": [
        "## **Supervised Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqyFFdRhfK4M",
        "colab_type": "text"
      },
      "source": [
        "Supervised learning is the machine learning task of learning a function that maps an input to an output based on example input-output pairs. It infers a function from labeled training data consisting of a set of training examples. A supervised learning algorithm analyzes the training data and produces an inferred function, which can be used for mapping new examples. An optimal scenario will allow for the algorithm to correctly determine the class labels for unseen instances. This requires the learning algorithm to generalize from the training data to unseen situations in a \"reasonable\" way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBVWQUCr3SkU",
        "colab_type": "text"
      },
      "source": [
        "### **1. Regression Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhMF_SSPe8nn",
        "colab_type": "text"
      },
      "source": [
        "Regression analysis is a set of statistical processes for estimating the relationships between a dependent variable (often called the 'outcome variable') and one or more independent variables (often called 'predictors', 'covariates', or 'features')."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzvzIks4hNit",
        "colab_type": "text"
      },
      "source": [
        "***a. Linear Regression***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhfHAEQbevjb",
        "colab_type": "text"
      },
      "source": [
        "Linear regression is a linear approach to modeling the relationship between a scalar response (or dependent variable) and one or more explanatory variables (or independent variables). The case of one explanatory variable is called simple linear regression. For more than one explanatory variable, the process is called multiple linear regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tji-5BawhdOP",
        "colab_type": "text"
      },
      "source": [
        "**Import Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGhjqZojhfKU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Dataset\n",
        "df_lifeexpectacy = pd.read_csv('https://raw.githubusercontent.com/dianrdn/data/master/life_expectacy.csv', sep=';')\n",
        "df_lifeexpectacy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TIZx9mahpEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prints the Dataset Information\n",
        "df_lifeexpectacy.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCA765vHw8Qi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prints Descriptive Statistics\n",
        "df_lifeexpectacy.describe().transpose()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZUweVEqxNxX",
        "colab_type": "text"
      },
      "source": [
        "**Modeling Linear Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEN9JkjjxR4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing Linear Regression Module\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Modeling Linear Regression\n",
        "lr = LinearRegression()\n",
        "\n",
        "# Select X and Y Variable\n",
        "X = df_lifeexpectacy.iloc[:, :-1].values\n",
        "Y = df_lifeexpectacy.iloc[:, 1].values\n",
        "\n",
        "# Apply Model to Data\n",
        "lr.fit(X, Y)\n",
        "\n",
        "# Show Coefficent and Intercept\n",
        "print('Coefficient = ', lr.coef_)\n",
        "print('Intercept =', lr.intercept_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlLFIn5cx5La",
        "colab_type": "text"
      },
      "source": [
        "**Visualizing Result**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHS7aAeXx7hP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Draw Scatter Plot with X and Y Axes\n",
        "plt.scatter(X, Y)\n",
        "\n",
        "# Show Regression Line with Green Color\n",
        "plt.plot(X, lr.predict(X), color = 'green')\n",
        "\n",
        "# Set Title and Axes Name\n",
        "plt.title('Life Expectacy')\n",
        "plt.xlabel('GDP')\n",
        "plt.ylabel('Life Expectacy')\n",
        "\n",
        "# Show Plot\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLdOajMO3_PL",
        "colab_type": "text"
      },
      "source": [
        "### **2. Classification Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxW-hOrgmQ2r",
        "colab_type": "text"
      },
      "source": [
        " classification is the problem of identifying to which of a set of categories (sub-populations) a new observation belongs, on the basis of a training set of data containing observations (or instances) whose category membership is known. Examples are assigning a given email to the \"spam\" or \"non-spam\" class, and assigning a diagnosis to a given patient based on observed characteristics of the patient (sex, blood pressure, presence or absence of certain symptoms, etc.). Classification is an example of pattern recognition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpxlBH9W3BE2",
        "colab_type": "text"
      },
      "source": [
        "***Decision Tree Classifier***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgOX-StZnMvN",
        "colab_type": "text"
      },
      "source": [
        "A decision tree is a flowchart-like tree structure where an internal node represents feature(or attribute), the branch represents a decision rule, and each leaf node represents the outcome. The topmost node in a decision tree is known as the root node. It learns to partition on the basis of the attribute value. It partitions the tree in recursively manner call recursive partitioning. This flowchart-like structure helps you in decision making."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8CmJkUsTzeYU"
      },
      "source": [
        "**Import Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qCEspOFVzeYV",
        "colab": {}
      },
      "source": [
        "# Import Dataset\n",
        "df_churn = pd.read_csv('https://raw.githubusercontent.com/dianrdn/data/master/customer_churn.csv', sep = ';')\n",
        "df_churn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B6o_x1hDzeYZ",
        "colab": {}
      },
      "source": [
        "# Prints the Dataset Information\n",
        "df_churn.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A-SxL5OwzeYc",
        "colab": {}
      },
      "source": [
        "# Prints Descriptive Statistics\n",
        "df_churn.describe().transpose()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OympUMG0sBV",
        "colab_type": "text"
      },
      "source": [
        "**Data Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mf6TfMDDwBee",
        "colab_type": "text"
      },
      "source": [
        "Handling Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlWqQPW_wDJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check for Missing Values\n",
        "df_churn.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urZMnUO1wGmU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Search for Median Value\n",
        "median = df_churn['TotalCharges'].median()\n",
        "\n",
        "# Use Median to Replace Missing Values\n",
        "df_churn['TotalCharges'].fillna(median, inplace=True)\n",
        "\n",
        "# Check for Missing Values\n",
        "df_churn.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxGx6X8zwTVG",
        "colab_type": "text"
      },
      "source": [
        "Encode Categorical Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOprAnLcwWWA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Module\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Encoder\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "# Encode Categorical Data\n",
        "df_encoded = pd.DataFrame(encoder.fit_transform(df_churn[['gender', 'InternetService', 'Contract', 'PaymentMethod']]))\n",
        "df_encoded.columns = encoder.get_feature_names(['gender', 'InternetService', 'Contract', 'PaymentMethod'])\n",
        "\n",
        "# Replace Categotical Data with Encoded Data\n",
        "df_churn.drop(['gender', 'InternetService', 'Contract', 'PaymentMethod'] ,axis=1, inplace=True)\n",
        "df_churn_encoded= pd.concat([df_churn, df_encoded], axis=1)\n",
        "\n",
        "# Show Encoded Dataframe\n",
        "df_churn_encoded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dm__QD8SxBqc",
        "colab_type": "text"
      },
      "source": [
        "Set Feature and Target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQFTig_v0klf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Select Features\n",
        "feature = df_churn_encoded.drop(['customerID', 'Churn'], axis=1)\n",
        "feature"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vacgNWxh0q_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Select Target\n",
        "target = df_churn_encoded['Churn']\n",
        "target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxni4q9HxU_h",
        "colab_type": "text"
      },
      "source": [
        "Set Training and Testing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcS1t1Rp020y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set Training and Testing Data (70:30)\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "feature_train, feature_test, target_train, target_test = train_test_split(feature , target, shuffle = True, test_size=0.3, random_state=1)\n",
        "\n",
        "# Show the Training and Testing Data\n",
        "print(feature_train.shape)\n",
        "print(feature_test.shape)\n",
        "print(target_train.shape)\n",
        "print(target_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9PDKadJ1JE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show Features\n",
        "feature"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqWTxIwa1M01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show Targets\n",
        "target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og5PrN9e1X0x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show the Training and Testing Data\n",
        "print(feature_train.shape)\n",
        "print(feature_test.shape)\n",
        "print(target_train.shape)\n",
        "print(target_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_jYRdpBotGt",
        "colab_type": "text"
      },
      "source": [
        "**Modeling Decision Tree Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5olHo38B4_ZR",
        "colab": {}
      },
      "source": [
        "# Import library\n",
        "from sklearn import tree\n",
        "\n",
        "# Modeling Decision Tree\n",
        "dtree = tree.DecisionTreeClassifier(min_impurity_decrease=0.01)\n",
        "dtree.fit(feature_train, target_train)\n",
        "\n",
        "# Predict Test Data \n",
        "target_predicted_dtree = dtree.predict(feature_test)\n",
        "target_predicted_dtree"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtpTZzrT15gH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize Tree\n",
        "\n",
        "from sklearn.externals.six import StringIO  \n",
        "from IPython.display import Image  \n",
        "from sklearn.tree import export_graphviz\n",
        "import pydotplus\n",
        "\n",
        "dot_data = StringIO()\n",
        "export_graphviz(dtree, out_file=dot_data,  \n",
        "                filled=True, rounded=True,\n",
        "                special_characters=True,\n",
        "                class_names=['notchurn', 'churn'],\n",
        "                feature_names=['SeniorCitizen',\t'Partner',\t'Dependents', 'tenure',\t'PhoneService', 'OnlineSecurity',\t'OnlineBackup',\t'DeviceProtection',\n",
        "                               'TechSupport',\t'StreamingTV',\t'StreamingMovies',\t'PaperlessBilling',\t'MonthlyCharges', 'TotalCharges', 'gender_Female',\n",
        "                               'gender_Male',\t'InternetService_DSL', 'InternetService_Fiber optic', 'InternetService_No',\t'Contract_Month-to-month',\n",
        "                               'Contract_One year',\t'Contract_Two year',\t'PaymentMethod_Bank transfer (automatic)', 'PaymentMethod_Credit card (automatic)',\n",
        "                               'PaymentMethod_Electronic check',\t'PaymentMethod_Mailed check'])\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "Image(graph.create_png())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzO27B92pKtD",
        "colab_type": "text"
      },
      "source": [
        "In the decision tree chart, each internal node has a decision rule that splits the data. Gini referred as Gini ratio, which measures the impurity of the node. You can say a node is pure (gini = 0) when all of its records belong to the same class, such nodes known as the leaf node.\n",
        "\n",
        "Samples is the sum of data train which actually belongs to the decision. The first node samples is equal to the whole data train number = 4930.\n",
        "\n",
        "Value is the sum of data train which is predicted belong to each of next node. For the first node, the values are [3589, 1341]. This means that 3589 data are predicted as notchurn, while 1341 data are predicted as churn.\n",
        "\n",
        "Class is stated the class categori. The class of the first node is 'notchurn'. So, the next step is, if the a data have a class of notchurn = true, we move to the left node, and vice versa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhxeRbuO1w9X",
        "colab_type": "text"
      },
      "source": [
        "**Model Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7m2XcUlQ4_ZV",
        "colab": {}
      },
      "source": [
        "# Confsion Matrix\n",
        "cm_dtree = metrics.confusion_matrix(target_test, target_predicted_dtree)\n",
        "cm_dtree"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuJaroTA33hl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Accuracy, Precision, Recall\n",
        "acc_dtree = metrics.accuracy_score(target_test, target_predicted_dtree)\n",
        "prec_dtree = metrics.precision_score(target_test, target_predicted_dtree)\n",
        "rec_dtree = metrics.recall_score(target_test, target_predicted_dtree)\n",
        "f1_dtree = metrics.f1_score(target_test, target_predicted_dtree)\n",
        "kappa_dtree = metrics.cohen_kappa_score(target_test, target_predicted_dtree)\n",
        "\n",
        "# Show Accuracy, Precision, Recall\n",
        "print('Accuracy:', acc_dtree )\n",
        "print('Precision:', prec_dtree)\n",
        "print('Recall:', rec_dtree)\n",
        "print('F1 Score:', f1_dtree)\n",
        "print('Cohens Kappa Score:', kappa_dtree)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCWRRoAh26gS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Visualization Package\n",
        "plt.rcParams['figure.figsize'] = (10, 10)\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "# Visualize ROC Curve\n",
        "target_predicted_dtree_prob = dtree.predict_proba(feature_test)[::,1]\n",
        "fp_rate_dtree, tp_rate_dtree, _ = metrics.roc_curve(target_test,  target_predicted_dtree_prob)\n",
        "auc_dtree = metrics.roc_auc_score(target_test, target_predicted_dtree_prob)\n",
        "plt.plot(fp_rate_dtree, tp_rate_dtree, label=\"Decision Tree, auc=\"+str(auc_dtree))\n",
        "plt.xlabel('false positive rate') \n",
        "plt.ylabel('true positive rate')\n",
        "plt.legend(loc=4)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RtrhtxiT0TcG"
      },
      "source": [
        "## **Unsupervised Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjQnEb-5uC4l",
        "colab_type": "text"
      },
      "source": [
        "Unsupervised learning is a type of machine learning that looks for previously undetected patterns in a data set with no pre-existing labels and with a minimum of human supervision. In contrast to supervised learning that usually makes use of human-labeled data, unsupervised learning, also known as self-organization allows for modeling of probability densities over inputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBT3lLL9UeGl",
        "colab_type": "text"
      },
      "source": [
        "### **1. Clustering Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ArTSxmKuXBc",
        "colab_type": "text"
      },
      "source": [
        "Cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense) to each other than to those in other groups (clusters)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5knTfWYeT3x",
        "colab_type": "text"
      },
      "source": [
        "***K-Means Clustering***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-LzlK8QvPWt",
        "colab_type": "text"
      },
      "source": [
        "Kmeans algorithm is an iterative algorithm that tries to partition the dataset into Kpre-defined distinct non-overlapping subgroups (clusters) where each data point belongs to only one group. It tries to make the inter-cluster data points as similar as possible while also keeping the clusters as different (far) as possible. It assigns data points to a cluster such that the sum of the squared distance between the data points and the clusterâ€™s centroid (arithmetic mean of all the data points that belong to that cluster) is at the minimum. The less variation we have within clusters, the more homogeneous (similar) the data points are within the same cluster."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xOKLZILWP_lC"
      },
      "source": [
        "**Import Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sk-AHvbGP_lD",
        "colab": {}
      },
      "source": [
        "# Import Dataset\n",
        "df_hdi = pd.read_csv('https://raw.githubusercontent.com/dianrdn/rc-dataanalytic/master/dataset/human_development_index.csv')\n",
        "df_hdi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aAs3kf2hP_lG",
        "colab": {}
      },
      "source": [
        "# Prints the Dataset Information\n",
        "df_hdi.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PGFHmTvTP_lK",
        "colab": {}
      },
      "source": [
        "# Prints Descriptive Statistics\n",
        "df_hdi.describe().transpose()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cRaWmk38P_lO"
      },
      "source": [
        "**Data Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oc0sRvtQ418Y",
        "colab_type": "text"
      },
      "source": [
        "First, we standardize the data to equalize the range and/or data variability. Feature standardization makes the values of each feature in the data have zero-mean (when subtracting the mean in the numerator) and unit-variance. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DJLkVFMSP_lR",
        "colab": {}
      },
      "source": [
        "# Importing Standardscalar Module \n",
        "from sklearn.preprocessing import StandardScaler \n",
        "\n",
        "# Set Name for StandardScaler as scaler\n",
        "scaler = StandardScaler() \n",
        "\n",
        "# Select Data\n",
        "df_standardized = df_hdi([['HDI', 'REVENUE']])\n",
        "\n",
        "# Fit Standardization\n",
        "column_names = df_standardized.columns.tolist()\n",
        "df_standardized[column_names] = scaler.fit_transform(df_standardized[column_names])\n",
        "df_standardized.sort_index(inplace=True)\n",
        "df_standardized"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jKNSDZ0tP_lX",
        "colab": {}
      },
      "source": [
        "# Styling Plot\n",
        "sns.set() \n",
        "plt.rcParams['figure.figsize'] = (16, 9)\n",
        "\n",
        "# Visualizing the Data\n",
        "sns.scatterplot(x='INCOME', y='SPEND', data=df_income)\n",
        "plt.title('Customer Segments')\n",
        "plt.xlabel('Annual Income')\n",
        "plt.ylabel('Annual Spend')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lptWQ-EpWUk",
        "colab_type": "text"
      },
      "source": [
        "**Modeling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Unebu5ajef8R",
        "colab_type": "text"
      },
      "source": [
        "**Search for the Optimum Number of Clusters (k)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pwgQESo_n9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transform Data Frame to Numpy Array\n",
        "income = df_income.to_numpy()\n",
        "income"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fl---X3eeKx9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Elbow Method\n",
        "from sklearn.cluster import KMeans\n",
        "wcss = []\n",
        "for i in range(1,11):\n",
        "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
        "    kmeans.fit(income)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "  \n",
        "# Visualize \n",
        "plt.plot(range(1,11),wcss)\n",
        "plt.title('Elbow Method')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('wcss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "490H6p_AerBM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Silhoutte Method\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "for n_cluster in range(2, 11):\n",
        "    kmeans = KMeans(n_clusters=n_cluster).fit(income)\n",
        "    label = kmeans.labels_\n",
        "    sil_coeff = silhouette_score(income, label, metric='euclidean')\n",
        "    print('For n_clusters={}, The Silhouette Coefficient is {}'.format(n_cluster, sil_coeff))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CHgU53qpKmd",
        "colab_type": "text"
      },
      "source": [
        "**Modeling K-Means Clustering**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5c5fGHieyID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Apply the K-Means Model to the Data\n",
        "kmeans = KMeans(n_clusters=3, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
        "cluster = kmeans.fit_predict(income)\n",
        "\n",
        "# Visualising Clusters for k=3\n",
        "sns.scatterplot(x='INCOME', y='SPEND', data=df_income)\n",
        "plt.scatter(income[cluster == 0, 0], income[cluster == 0, 1], s = 50, label = 'Cluster 1')\n",
        "plt.scatter(income[cluster == 1, 0], income[cluster == 1, 1], s = 50, label = 'Cluster 2')\n",
        "plt.scatter(income[cluster == 2, 0], income[cluster == 2, 1], s = 50, label = 'Cluster 3')\n",
        "plt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1],s=200,marker='s', alpha=0.7, label='Centroids')\n",
        "plt.title('Customer segments')\n",
        "plt.xlabel('Annual income')\n",
        "plt.ylabel('Annual spend')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}